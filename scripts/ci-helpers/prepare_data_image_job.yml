include:
  - project: 'hive/hive'
    ref: f80071a140ec9eca0bac02a2662ec760cb1813f6 #develop
    file: '/scripts/ci-helpers/prepare_data_image_job.yml' 

.prepare_haf_image:
  extends: .docker_image_builder_job

  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR"
    SCRIPTS_PATH: "$SUBMODULE_DIR/scripts"
    REGISTRY_USER: "$CI_IMG_BUILDER_USER"
    REGISTRY_PASS: $CI_IMG_BUILDER_PASSWORD
    BINARY_CACHE_PATH: "hived-binaries"
    HIVE_NETWORK_TYPE: mainnet
  script:
    - $SCRIPTS_PATH/ci-helpers/get_image4submodule.sh
        "$SUBMODULE_DIR" registry.gitlab.syncad.com/hive/haf/ HAF "$REGISTRY_USER" "$REGISTRY_PASS"
        --export-binaries="$BINARY_CACHE_PATH" --network-type="$HIVE_NETWORK_TYPE"
    - chmod -Rc a+rwx "$BINARY_CACHE_PATH"
    - ls -la ./$BINARY_CACHE_PATH/*

  artifacts:
    reports:
      dotenv: docker_image_name.env
    paths:
      - ./$BINARY_CACHE_PATH/*
      - ./docker_image_name.env

.prepare_haf_data_5m:
  extends: .docker_image_builder_job

  variables:
    SUBMODULE_DIR: "$CI_PROJECT_DIR"
    SCRIPTS_PATH: "$SUBMODULE_DIR/scripts"
    BLOCK_LOG_SOURCE_DIR: ""
    CONFIG_INI_SOURCE: ""
    HIVE_NETWORK_TYPE: mainnet
  script:
    - mkdir "${DATA_CACHE_HAF_PREFIX}_${HAF_COMMIT}/datadir" -p
    - flock "${DATA_CACHE_HAF_PREFIX}_${HAF_COMMIT}/datadir" $SCRIPTS_PATH/ci-helpers/build_data.sh $HAF_IMAGE_NAME
        --data-cache="${DATA_CACHE_HAF_PREFIX}_${HAF_COMMIT}" --block-log-source-dir="$BLOCK_LOG_SOURCE_DIR" --config-ini-source="$CONFIG_INI_SOURCE"
    - cp "${DATA_CACHE_HAF_PREFIX}_${HAF_COMMIT}/datadir/docker_entrypoint.log" "$CI_PROJECT_DIR"
    - echo "HIVED_UID=$(id -u)" > hived_uid.env
    - cat hived_uid.env

  artifacts:
    reports:
      dotenv:
        - docker_image_name.env
        - hived_uid.env
    paths:
    - docker_entrypoint.log
