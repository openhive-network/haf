stages:
  - build_and_test_phase_1
  - build_and_test_phase_2
  - docker_build
  - deploy
  - cleanup
  - publish

variables:
  PYTEST_NUMBER_OF_PROCESSES: 8
  CTEST_NUMBER_OF_JOBS: 4
  GIT_DEPTH: 20
  GIT_SUBMODULE_STRATEGY: recursive
  FF_ENABLE_JOB_CLEANUP: 1
  GIT_STRATEGY: clone
  # uses registry.gitlab.syncad.com/hive/haf/ci-base-image:ubuntu22.04-7
  BUILDER_IMAGE_TAG: "@sha256:0833e23192dc87574e0cb83ca82496798089a243fa8a43055814a9b3d4188e15"
  CI_DEBUG_SERVICES: "true"
  SETUP_SCRIPTS_PATH: "$CI_PROJECT_DIR/scripts"
  TEST_TOOLS_NODE_DEFAULT_WAIT_FOR_LIVE_TIMEOUT: 60
  DATA_CACHE_HAF_PREFIX: "/cache/replay_data_haf"
  BLOCK_LOG_SOURCE_DIR_5M: /blockchain/block_log_5m
  SNAPSHOTS_PATH: /cache/snapshots_pipeline_${CI_PIPELINE_ID}
  BLOCK_LOG_SOURCE_DIR_MIRRORNET_5M: /cache/block_log_5m_mirrornet

include:
  - template: Workflows/Branch-Pipelines.gitlab-ci.yml
  - local: '/scripts/ci-helpers/prepare_data_image_job.yml'
  - project: 'hive/common-ci-configuration'
    ref: 337fabaa5cd03019e9b82dd7df32121783c9391e
    file:
    - '/templates/python_projects.gitlab-ci.yml'

verify_poetry_lock_sanity:
  extends: .verify_poetry_lock_sanity_template
  stage: build_and_test_phase_1
  variables:
    PYPROJECT_DIR: "$CI_PROJECT_DIR/tests/integration/haf-local-tools"

  tags:
    - public-runner-docker

.haf_image_build:
  extends: .prepare_haf_image
  stage: build_and_test_phase_1
  tags:
    - public-runner-docker
    - hived-for-tests

haf_image_build_mirrornet:
  extends: .haf_image_build
  variables:
    BINARY_CACHE_PATH: "haf-mirrornet-binaries"
    HIVE_NETWORK_TYPE: mirrornet

.haf-service: &haf-service
  name: $HAF_IMAGE_NAME
  alias: haf-instance
  variables:
    # Allow access from any network to eliminate CI IP addressing problems when hfm runs as service
    PG_ACCESS: |
                "host    all              haf_admin        0.0.0.0/0    trust"
                "host    all              haf_app_admin    0.0.0.0/0    trust"
    DATA_SOURCE: "${DATA_CACHE_HAF_PREFIX}_${HAF_COMMIT}"
    LOG_FILE: $CI_JOB_NAME.log
  command: ["--replay-blockchain", "--stop-replay-at-block=5000000"]

.hfm-only-service: &hfm-only-service
  name: $HAF_IMAGE_NAME
  alias: hfm-only-instance
  variables:
    # Allow access from any network to eliminate CI IP addressing problems when hfm runs as service
    PG_ACCESS: |
                "host    all              haf_admin        0.0.0.0/0    trust"
                "host    all              haf_app_admin    0.0.0.0/0    trust"
                "host    all              all              0.0.0.0/0    scram-sha-256"
  command: [ "--execute-maintenance-script=${HAF_SOURCE_DIR}/scripts/maintenance-scripts/sleep_infinity.sh" ]

.pytest_based:
  extends: .job-defaults
  before_script:
    - |
      echo -e "\e[0Ksection_start:$(date +%s):python_venv[collapsed=true]\r\e[0KCreating Python virtual environment..."
      python3 -m venv --system-site-packages venv/
      . venv/bin/activate
      (cd $CI_PROJECT_DIR/tests/integration/haf-local-tools && poetry install)
      echo -e "\e[0Ksection_end:$(date +%s):python_venv\r\e[0K"


dump_snapshot_5m_mirrornet:
  extends: .job-defaults
  stage: build_and_test_phase_1
  needs:
  - job: haf_image_build_mirrornet
    artifacts: true
  image: "$CI_REGISTRY_IMAGE/ci-base-image$BUILDER_IMAGE_TAG"
  variables:
    MIRRORNET_WORKING_DIR: "$CI_PROJECT_DIR/mirrornet_witness_node"
    BINARY_CACHE_PATH: "haf-mirrornet-binaries"
    HIVED_PATH: "$CI_PROJECT_DIR/$BINARY_CACHE_PATH/hived"
  script:
    #Prepare environment for hived run
    - cd $CI_PROJECT_DIR/docker
    - mkdir $MIRRORNET_WORKING_DIR
    - cd $MIRRORNET_WORKING_DIR
    - mkdir blockchain
    - cd blockchain
    - cp $BLOCK_LOG_SOURCE_DIR_MIRRORNET_5M/block_log .
    #Prepare snapshot storage
    - mkdir $SNAPSHOTS_PATH
    - cd $SNAPSHOTS_PATH
    - mkdir 5m_mirrornet
    #Prepare snapshot
    - $HIVED_PATH -d $MIRRORNET_WORKING_DIR --exit-before-sync --replay
    - echo "plugin = state_snapshot" >> $MIRRORNET_WORKING_DIR/config.ini
    - $HIVED_PATH -d $MIRRORNET_WORKING_DIR --dump-snapshot=snapshot --exit-before-sync
    #Store snapshot in cache
    - mv $MIRRORNET_WORKING_DIR/blockchain $SNAPSHOTS_PATH/5m_mirrornet
    - mv $MIRRORNET_WORKING_DIR/snapshot/snapshot $SNAPSHOTS_PATH/5m_mirrornet
  tags:
    - data-cache-storage

haf_system_tests_mirrornet:
  stage: build_and_test_phase_2
  extends: .pytest_based
  timeout: 2h
  needs:
    - job: haf_image_build_mirrornet
      artifacts: true
    - job: dump_snapshot_5m_mirrornet
      artifacts: false
  image: "$CI_REGISTRY_IMAGE/ci-base-image$BUILDER_IMAGE_TAG"
  services:
    - *hfm-only-service
  variables:
    BINARY_CACHE_PATH: "haf-mirrornet-binaries"
    HIVED_PATH: "$CI_PROJECT_DIR/$BINARY_CACHE_PATH/hived"
    COMPRESS_BLOCK_LOG_PATH: "$CI_PROJECT_DIR/$BINARY_CACHE_PATH/compress_block_log"
    GET_DEV_KEY_PATH: "$CI_PROJECT_DIR/$BINARY_CACHE_PATH/get_dev_key"
    CLI_WALLET_PATH: "$CI_PROJECT_DIR/$BINARY_CACHE_PATH/cli_wallet"
    DB_NAME: haf_block_log
    DB_URL: "postgresql://haf_admin@hfm-only-instance:5432/$DB_NAME"
  script:
    # check that postgres service is ready
    - psql "$DB_URL" -c "SELECT 1"
    - mkdir $CI_PROJECT_DIR/tests/integration/system/haf/mirrornet_tests/tmp_block_log
    # This cp and call to compress_block_log is to keep backcompatibility with pipelines on master branch (where still 1.27.X line is present until next HF will apply),
    # where nodes does not support new format of block_log.artifacts file;
    # Issue: https://gitlab.syncad.com/hive/haf/-/issues/151
    # copy block_log to tmp location
    - cp $BLOCK_LOG_SOURCE_DIR_MIRRORNET_5M/block_log $CI_PROJECT_DIR/tests/integration/system/haf/mirrornet_tests/tmp_block_log
    # copy block_log and generate new artifacts with compress_block_log util
    - time $COMPRESS_BLOCK_LOG_PATH --input-block-log $CI_PROJECT_DIR/tests/integration/system/haf/mirrornet_tests/tmp_block_log -o $CI_PROJECT_DIR/tests/integration/system/haf/mirrornet_tests --decompress
    # drop tmp location
    - rm -r $CI_PROJECT_DIR/tests/integration/system/haf/mirrornet_tests/tmp_block_log
    # prepare environment and run tests
    - cd $CI_PROJECT_DIR/tests/integration/system/haf/mirrornet_tests
    - pytest --junitxml report.xml --timeout=3600 --block-log-path=$CI_PROJECT_DIR/tests/integration/system/haf/mirrornet_tests/block_log --snapshot-path=$SNAPSHOTS_PATH/5m_mirrornet/snapshot -n ${PYTEST_NUMBER_OF_PROCESSES} -m mirrornet
  artifacts:
    paths:
    - "**/generated_during_*"
    - "**/generated_by_package_fixtures"
    exclude:
    - "**/generated_during_*/**/block_log"
    - "**/generated_during_*/**/block_log.artifacts"
    - "**/generated_during_*/**/shared_memory.bin"
    - "**/generated_during_*/**/*.sst"
    reports:
      junit: tests/integration/system/haf/mirrornet_tests/report.xml
    when: always
    expire_in: 1 week
  interruptible: true
  tags:
    - data-cache-storage


cleanup_haf_cache_manual:
  extends: .cleanup_cache_manual
  stage: cleanup
  variables:
    CLEANUP_PATH_PATTERN: "/cache/replay_data_haf_*"
  tags:
    - data-cache-storage

cleanup_haf_snapshot_from_cache:
  extends: .cleanup_cache_manual
  stage: cleanup
  variables:
    CLEANUP_PATH_PATTERN: "/cache/snapshots_pipeline_*"
  tags:
    - data-cache-storage

build_and_publish_image:
  stage: publish
  extends: .publish_docker_image_template
  script:
    - scripts/ci-helpers/build_and_publish_instance.sh
  tags:
    - public-runner-docker

